{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2.0 Linear Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mic0331/deep-learning-tensorflow-2/blob/master/TF2_0_Linear_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uKexCgeV-l_",
        "colab_type": "code",
        "outputId": "ee470cf0-3b6a-4650-f945-e12a6705c65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Install TensorFlow\n",
        "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x  # Colab only.\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFHSPY_aWMNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the data\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axQIBVErWUMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the data\n",
        "data = load_breast_cancer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xit8_JcCWZ8c",
        "colab_type": "code",
        "outputId": "d1163468-66a5-4c10-8318-660cedd34783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check the type of `data` \n",
        "type(data)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.utils.Bunch"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXG1Jdk5Wm0T",
        "colab_type": "code",
        "outputId": "b4ea9f74-7861-424e-d37e-990c440d380c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# note: it is a Bunch object\n",
        "# this basically acts like a dictionary where you can treat the keys like attributes\n",
        "data.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-bmRURQWpZ_",
        "colab_type": "code",
        "outputId": "c2cecc14-d771-404c-e1f6-6e1d5865a8d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 'data' (the attribute) means the input data\n",
        "data.data.shape\n",
        "# it has 569 samples, 30 features"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQJlFgaaWr9K",
        "colab_type": "code",
        "outputId": "dacfc0e4-cab4-4fcb-8444-0d3ac5bfc3ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# 'targets'\n",
        "data.target\n",
        "# note how the targets are just 0s and 1s\n",
        "# normally, when you have K targets, they are labeled 0..K-1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFvTknwuW6Nk",
        "colab_type": "code",
        "outputId": "3a6f9401-7a57-409c-9087-2c71fb879f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# their meaning is not lost\n",
        "data.target_names"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWbKNZ4BW-3L",
        "colab_type": "code",
        "outputId": "5fd958d5-f0cd-486f-ce29-4b6f725a33d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# there are also 569 corresponding targets\n",
        "data.target.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGi6rINbXFOE",
        "colab_type": "code",
        "outputId": "69dcde6a-8e1b-4ca0-ada8-6f4fd8f0da48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# you can also determine the meaning of each feature\n",
        "data.feature_names"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLvVL5b3XQ7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split the data into train and test sets\n",
        "# this lets us simulate how our model will perform in the future\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33)\n",
        "N, D = X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEcU41YcXnJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRw3OAP4X036",
        "colab_type": "code",
        "outputId": "c73274ee-01f3-4427-99a9-fbf2e403a37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Build the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(D,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Alternatively, you can do:\n",
        "#model = tf.keras.models.Sequential()\n",
        "#model.add(tf.keras.layers.Dense(1, input_shape=(D,), activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "r = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 381 samples, validate on 188 samples\n",
            "Epoch 1/100\n",
            "381/381 [==============================] - 0s 674us/sample - loss: 1.5990 - accuracy: 0.2100 - val_loss: 1.4978 - val_accuracy: 0.1277\n",
            "Epoch 2/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 1.4721 - accuracy: 0.2283 - val_loss: 1.3683 - val_accuracy: 0.1436\n",
            "Epoch 3/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 1.3560 - accuracy: 0.2441 - val_loss: 1.2452 - val_accuracy: 0.1702\n",
            "Epoch 4/100\n",
            "381/381 [==============================] - 0s 97us/sample - loss: 1.2428 - accuracy: 0.2808 - val_loss: 1.1341 - val_accuracy: 0.2340\n",
            "Epoch 5/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 1.1395 - accuracy: 0.3202 - val_loss: 1.0345 - val_accuracy: 0.3085\n",
            "Epoch 6/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 1.0494 - accuracy: 0.3517 - val_loss: 0.9428 - val_accuracy: 0.3723\n",
            "Epoch 7/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.9641 - accuracy: 0.4304 - val_loss: 0.8628 - val_accuracy: 0.4574\n",
            "Epoch 8/100\n",
            "381/381 [==============================] - 0s 79us/sample - loss: 0.8904 - accuracy: 0.4619 - val_loss: 0.7907 - val_accuracy: 0.5319\n",
            "Epoch 9/100\n",
            "381/381 [==============================] - 0s 99us/sample - loss: 0.8238 - accuracy: 0.4987 - val_loss: 0.7273 - val_accuracy: 0.6223\n",
            "Epoch 10/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 0.7649 - accuracy: 0.5459 - val_loss: 0.6718 - val_accuracy: 0.6702\n",
            "Epoch 11/100\n",
            "381/381 [==============================] - 0s 77us/sample - loss: 0.7125 - accuracy: 0.5827 - val_loss: 0.6235 - val_accuracy: 0.7021\n",
            "Epoch 12/100\n",
            "381/381 [==============================] - 0s 80us/sample - loss: 0.6672 - accuracy: 0.6352 - val_loss: 0.5804 - val_accuracy: 0.7340\n",
            "Epoch 13/100\n",
            "381/381 [==============================] - 0s 82us/sample - loss: 0.6267 - accuracy: 0.6667 - val_loss: 0.5426 - val_accuracy: 0.7660\n",
            "Epoch 14/100\n",
            "381/381 [==============================] - 0s 84us/sample - loss: 0.5912 - accuracy: 0.7087 - val_loss: 0.5090 - val_accuracy: 0.7819\n",
            "Epoch 15/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 0.5592 - accuracy: 0.7559 - val_loss: 0.4790 - val_accuracy: 0.7979\n",
            "Epoch 16/100\n",
            "381/381 [==============================] - 0s 92us/sample - loss: 0.5308 - accuracy: 0.7769 - val_loss: 0.4522 - val_accuracy: 0.8138\n",
            "Epoch 17/100\n",
            "381/381 [==============================] - 0s 82us/sample - loss: 0.5047 - accuracy: 0.7900 - val_loss: 0.4294 - val_accuracy: 0.8245\n",
            "Epoch 18/100\n",
            "381/381 [==============================] - 0s 79us/sample - loss: 0.4822 - accuracy: 0.8136 - val_loss: 0.4076 - val_accuracy: 0.8404\n",
            "Epoch 19/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.4610 - accuracy: 0.8215 - val_loss: 0.3886 - val_accuracy: 0.8564\n",
            "Epoch 20/100\n",
            "381/381 [==============================] - 0s 80us/sample - loss: 0.4422 - accuracy: 0.8320 - val_loss: 0.3713 - val_accuracy: 0.8723\n",
            "Epoch 21/100\n",
            "381/381 [==============================] - 0s 104us/sample - loss: 0.4248 - accuracy: 0.8478 - val_loss: 0.3553 - val_accuracy: 0.8723\n",
            "Epoch 22/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 0.4089 - accuracy: 0.8609 - val_loss: 0.3411 - val_accuracy: 0.8777\n",
            "Epoch 23/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.3946 - accuracy: 0.8714 - val_loss: 0.3276 - val_accuracy: 0.8883\n",
            "Epoch 24/100\n",
            "381/381 [==============================] - 0s 95us/sample - loss: 0.3809 - accuracy: 0.8766 - val_loss: 0.3153 - val_accuracy: 0.8936\n",
            "Epoch 25/100\n",
            "381/381 [==============================] - 0s 96us/sample - loss: 0.3684 - accuracy: 0.8898 - val_loss: 0.3039 - val_accuracy: 0.9043\n",
            "Epoch 26/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.3569 - accuracy: 0.8950 - val_loss: 0.2935 - val_accuracy: 0.9043\n",
            "Epoch 27/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 0.3460 - accuracy: 0.8976 - val_loss: 0.2839 - val_accuracy: 0.9096\n",
            "Epoch 28/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.3359 - accuracy: 0.9055 - val_loss: 0.2749 - val_accuracy: 0.9202\n",
            "Epoch 29/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.3265 - accuracy: 0.9055 - val_loss: 0.2665 - val_accuracy: 0.9202\n",
            "Epoch 30/100\n",
            "381/381 [==============================] - 0s 77us/sample - loss: 0.3175 - accuracy: 0.9081 - val_loss: 0.2588 - val_accuracy: 0.9202\n",
            "Epoch 31/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.3093 - accuracy: 0.9134 - val_loss: 0.2514 - val_accuracy: 0.9255\n",
            "Epoch 32/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.3013 - accuracy: 0.9186 - val_loss: 0.2447 - val_accuracy: 0.9255\n",
            "Epoch 33/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.2938 - accuracy: 0.9213 - val_loss: 0.2381 - val_accuracy: 0.9255\n",
            "Epoch 34/100\n",
            "381/381 [==============================] - 0s 76us/sample - loss: 0.2868 - accuracy: 0.9265 - val_loss: 0.2319 - val_accuracy: 0.9309\n",
            "Epoch 35/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.2801 - accuracy: 0.9265 - val_loss: 0.2261 - val_accuracy: 0.9362\n",
            "Epoch 36/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.2739 - accuracy: 0.9265 - val_loss: 0.2206 - val_accuracy: 0.9415\n",
            "Epoch 37/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.2677 - accuracy: 0.9291 - val_loss: 0.2155 - val_accuracy: 0.9415\n",
            "Epoch 38/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.2619 - accuracy: 0.9291 - val_loss: 0.2106 - val_accuracy: 0.9468\n",
            "Epoch 39/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.2567 - accuracy: 0.9291 - val_loss: 0.2059 - val_accuracy: 0.9521\n",
            "Epoch 40/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.2513 - accuracy: 0.9291 - val_loss: 0.2015 - val_accuracy: 0.9521\n",
            "Epoch 41/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.2463 - accuracy: 0.9291 - val_loss: 0.1974 - val_accuracy: 0.9521\n",
            "Epoch 42/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.2417 - accuracy: 0.9318 - val_loss: 0.1934 - val_accuracy: 0.9521\n",
            "Epoch 43/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.2371 - accuracy: 0.9318 - val_loss: 0.1896 - val_accuracy: 0.9574\n",
            "Epoch 44/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.2327 - accuracy: 0.9318 - val_loss: 0.1860 - val_accuracy: 0.9628\n",
            "Epoch 45/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.2287 - accuracy: 0.9344 - val_loss: 0.1825 - val_accuracy: 0.9628\n",
            "Epoch 46/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.2246 - accuracy: 0.9370 - val_loss: 0.1792 - val_accuracy: 0.9628\n",
            "Epoch 47/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.2209 - accuracy: 0.9370 - val_loss: 0.1761 - val_accuracy: 0.9628\n",
            "Epoch 48/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.2172 - accuracy: 0.9344 - val_loss: 0.1730 - val_accuracy: 0.9628\n",
            "Epoch 49/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.2137 - accuracy: 0.9370 - val_loss: 0.1702 - val_accuracy: 0.9628\n",
            "Epoch 50/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.2103 - accuracy: 0.9396 - val_loss: 0.1674 - val_accuracy: 0.9628\n",
            "Epoch 51/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 0.2072 - accuracy: 0.9423 - val_loss: 0.1647 - val_accuracy: 0.9628\n",
            "Epoch 52/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 0.2039 - accuracy: 0.9423 - val_loss: 0.1621 - val_accuracy: 0.9681\n",
            "Epoch 53/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.2009 - accuracy: 0.9423 - val_loss: 0.1596 - val_accuracy: 0.9681\n",
            "Epoch 54/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.1981 - accuracy: 0.9423 - val_loss: 0.1573 - val_accuracy: 0.9734\n",
            "Epoch 55/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.1954 - accuracy: 0.9423 - val_loss: 0.1551 - val_accuracy: 0.9734\n",
            "Epoch 56/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 0.1927 - accuracy: 0.9449 - val_loss: 0.1529 - val_accuracy: 0.9734\n",
            "Epoch 57/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.1900 - accuracy: 0.9449 - val_loss: 0.1507 - val_accuracy: 0.9734\n",
            "Epoch 58/100\n",
            "381/381 [==============================] - 0s 113us/sample - loss: 0.1877 - accuracy: 0.9501 - val_loss: 0.1486 - val_accuracy: 0.9734\n",
            "Epoch 59/100\n",
            "381/381 [==============================] - 0s 86us/sample - loss: 0.1852 - accuracy: 0.9501 - val_loss: 0.1466 - val_accuracy: 0.9734\n",
            "Epoch 60/100\n",
            "381/381 [==============================] - 0s 89us/sample - loss: 0.1829 - accuracy: 0.9554 - val_loss: 0.1447 - val_accuracy: 0.9734\n",
            "Epoch 61/100\n",
            "381/381 [==============================] - 0s 91us/sample - loss: 0.1807 - accuracy: 0.9554 - val_loss: 0.1428 - val_accuracy: 0.9734\n",
            "Epoch 62/100\n",
            "381/381 [==============================] - 0s 80us/sample - loss: 0.1785 - accuracy: 0.9554 - val_loss: 0.1411 - val_accuracy: 0.9734\n",
            "Epoch 63/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.1765 - accuracy: 0.9554 - val_loss: 0.1394 - val_accuracy: 0.9734\n",
            "Epoch 64/100\n",
            "381/381 [==============================] - 0s 79us/sample - loss: 0.1745 - accuracy: 0.9554 - val_loss: 0.1377 - val_accuracy: 0.9734\n",
            "Epoch 65/100\n",
            "381/381 [==============================] - 0s 70us/sample - loss: 0.1725 - accuracy: 0.9554 - val_loss: 0.1361 - val_accuracy: 0.9734\n",
            "Epoch 66/100\n",
            "381/381 [==============================] - 0s 71us/sample - loss: 0.1707 - accuracy: 0.9554 - val_loss: 0.1346 - val_accuracy: 0.9734\n",
            "Epoch 67/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.1689 - accuracy: 0.9554 - val_loss: 0.1331 - val_accuracy: 0.9734\n",
            "Epoch 68/100\n",
            "381/381 [==============================] - 0s 84us/sample - loss: 0.1673 - accuracy: 0.9580 - val_loss: 0.1315 - val_accuracy: 0.9734\n",
            "Epoch 69/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.1655 - accuracy: 0.9606 - val_loss: 0.1301 - val_accuracy: 0.9734\n",
            "Epoch 70/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.1638 - accuracy: 0.9606 - val_loss: 0.1288 - val_accuracy: 0.9787\n",
            "Epoch 71/100\n",
            "381/381 [==============================] - 0s 86us/sample - loss: 0.1623 - accuracy: 0.9606 - val_loss: 0.1274 - val_accuracy: 0.9787\n",
            "Epoch 72/100\n",
            "381/381 [==============================] - 0s 95us/sample - loss: 0.1607 - accuracy: 0.9606 - val_loss: 0.1262 - val_accuracy: 0.9787\n",
            "Epoch 73/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.1592 - accuracy: 0.9606 - val_loss: 0.1248 - val_accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.1579 - accuracy: 0.9606 - val_loss: 0.1236 - val_accuracy: 0.9787\n",
            "Epoch 75/100\n",
            "381/381 [==============================] - 0s 77us/sample - loss: 0.1564 - accuracy: 0.9633 - val_loss: 0.1224 - val_accuracy: 0.9787\n",
            "Epoch 76/100\n",
            "381/381 [==============================] - 0s 89us/sample - loss: 0.1551 - accuracy: 0.9633 - val_loss: 0.1213 - val_accuracy: 0.9787\n",
            "Epoch 77/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.1537 - accuracy: 0.9633 - val_loss: 0.1201 - val_accuracy: 0.9787\n",
            "Epoch 78/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.1525 - accuracy: 0.9633 - val_loss: 0.1190 - val_accuracy: 0.9787\n",
            "Epoch 79/100\n",
            "381/381 [==============================] - 0s 82us/sample - loss: 0.1512 - accuracy: 0.9633 - val_loss: 0.1179 - val_accuracy: 0.9787\n",
            "Epoch 80/100\n",
            "381/381 [==============================] - 0s 77us/sample - loss: 0.1501 - accuracy: 0.9633 - val_loss: 0.1169 - val_accuracy: 0.9787\n",
            "Epoch 81/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.1489 - accuracy: 0.9633 - val_loss: 0.1159 - val_accuracy: 0.9787\n",
            "Epoch 82/100\n",
            "381/381 [==============================] - 0s 81us/sample - loss: 0.1478 - accuracy: 0.9633 - val_loss: 0.1149 - val_accuracy: 0.9787\n",
            "Epoch 83/100\n",
            "381/381 [==============================] - 0s 69us/sample - loss: 0.1466 - accuracy: 0.9633 - val_loss: 0.1139 - val_accuracy: 0.9787\n",
            "Epoch 84/100\n",
            "381/381 [==============================] - 0s 77us/sample - loss: 0.1456 - accuracy: 0.9633 - val_loss: 0.1129 - val_accuracy: 0.9787\n",
            "Epoch 85/100\n",
            "381/381 [==============================] - 0s 72us/sample - loss: 0.1446 - accuracy: 0.9633 - val_loss: 0.1120 - val_accuracy: 0.9787\n",
            "Epoch 86/100\n",
            "381/381 [==============================] - 0s 68us/sample - loss: 0.1435 - accuracy: 0.9633 - val_loss: 0.1112 - val_accuracy: 0.9787\n",
            "Epoch 87/100\n",
            "381/381 [==============================] - 0s 78us/sample - loss: 0.1425 - accuracy: 0.9633 - val_loss: 0.1102 - val_accuracy: 0.9787\n",
            "Epoch 88/100\n",
            "381/381 [==============================] - 0s 86us/sample - loss: 0.1415 - accuracy: 0.9633 - val_loss: 0.1094 - val_accuracy: 0.9787\n",
            "Epoch 89/100\n",
            "381/381 [==============================] - 0s 74us/sample - loss: 0.1406 - accuracy: 0.9633 - val_loss: 0.1085 - val_accuracy: 0.9787\n",
            "Epoch 90/100\n",
            "381/381 [==============================] - 0s 95us/sample - loss: 0.1397 - accuracy: 0.9633 - val_loss: 0.1077 - val_accuracy: 0.9787\n",
            "Epoch 91/100\n",
            "381/381 [==============================] - 0s 89us/sample - loss: 0.1388 - accuracy: 0.9633 - val_loss: 0.1069 - val_accuracy: 0.9787\n",
            "Epoch 92/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.1379 - accuracy: 0.9633 - val_loss: 0.1062 - val_accuracy: 0.9787\n",
            "Epoch 93/100\n",
            "381/381 [==============================] - 0s 79us/sample - loss: 0.1370 - accuracy: 0.9633 - val_loss: 0.1054 - val_accuracy: 0.9787\n",
            "Epoch 94/100\n",
            "381/381 [==============================] - 0s 80us/sample - loss: 0.1362 - accuracy: 0.9633 - val_loss: 0.1046 - val_accuracy: 0.9787\n",
            "Epoch 95/100\n",
            "381/381 [==============================] - 0s 75us/sample - loss: 0.1354 - accuracy: 0.9633 - val_loss: 0.1039 - val_accuracy: 0.9787\n",
            "Epoch 96/100\n",
            "381/381 [==============================] - 0s 73us/sample - loss: 0.1346 - accuracy: 0.9633 - val_loss: 0.1032 - val_accuracy: 0.9787\n",
            "Epoch 97/100\n",
            "381/381 [==============================] - 0s 82us/sample - loss: 0.1339 - accuracy: 0.9633 - val_loss: 0.1025 - val_accuracy: 0.9787\n",
            "Epoch 98/100\n",
            "381/381 [==============================] - 0s 89us/sample - loss: 0.1331 - accuracy: 0.9633 - val_loss: 0.1017 - val_accuracy: 0.9787\n",
            "Epoch 99/100\n",
            "381/381 [==============================] - 0s 83us/sample - loss: 0.1323 - accuracy: 0.9633 - val_loss: 0.1011 - val_accuracy: 0.9787\n",
            "Epoch 100/100\n",
            "381/381 [==============================] - 0s 79us/sample - loss: 0.1316 - accuracy: 0.9633 - val_loss: 0.1004 - val_accuracy: 0.9787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qevAh3knY03c",
        "colab_type": "code",
        "outputId": "281858a7-5c64-4d97-c43a-21a485cd2d24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Evaluate what's returned by model.fit()\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0ca99c1d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKaWC0P8HLWeZG9QQ6SEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NUlpAtPZQTx",
        "colab_type": "code",
        "outputId": "73b3f113-de60-47e8-e116-15eb5c74de09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Plot the accuracy too\n",
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0ca99b04e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0rbvmii3r1gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK49aaeMmtWo",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W4P73XZmqdF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9566a49a-6ceb-4841-881e-30119263a68c"
      },
      "source": [
        "# Make predictions\n",
        "P = model.predict(X_test)\n",
        "print(P) # they are outputs of the sigmoid, interpreted as probabilities p(y = 1 | x)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.95634675e-01]\n",
            " [8.53578269e-01]\n",
            " [9.80750263e-01]\n",
            " [1.04948878e-03]\n",
            " [9.97470200e-01]\n",
            " [7.13147938e-01]\n",
            " [9.97585893e-01]\n",
            " [9.70178843e-01]\n",
            " [1.88648701e-05]\n",
            " [5.73891401e-03]\n",
            " [9.30439472e-01]\n",
            " [9.95398462e-01]\n",
            " [9.97705102e-01]\n",
            " [9.79681134e-01]\n",
            " [1.55568123e-04]\n",
            " [9.93834019e-01]\n",
            " [4.24754322e-01]\n",
            " [9.94263887e-01]\n",
            " [8.18398654e-01]\n",
            " [9.97120380e-01]\n",
            " [9.61253762e-01]\n",
            " [9.64709520e-02]\n",
            " [1.45212412e-02]\n",
            " [2.10094452e-03]\n",
            " [9.89977598e-01]\n",
            " [9.12945628e-01]\n",
            " [4.10071015e-03]\n",
            " [9.92980361e-01]\n",
            " [1.10828876e-01]\n",
            " [1.66952014e-02]\n",
            " [8.87334347e-03]\n",
            " [5.04116416e-02]\n",
            " [2.96184421e-03]\n",
            " [1.31531477e-01]\n",
            " [9.79008198e-01]\n",
            " [9.89788651e-01]\n",
            " [9.59603786e-01]\n",
            " [9.98583615e-01]\n",
            " [9.68000531e-01]\n",
            " [2.15241224e-01]\n",
            " [9.84939694e-01]\n",
            " [4.38004732e-04]\n",
            " [1.27042711e-01]\n",
            " [9.76552248e-01]\n",
            " [6.30170107e-03]\n",
            " [4.19488549e-03]\n",
            " [8.80793512e-01]\n",
            " [9.48599339e-01]\n",
            " [9.95938778e-01]\n",
            " [1.10763609e-01]\n",
            " [7.22929120e-01]\n",
            " [9.86760497e-01]\n",
            " [9.72992539e-01]\n",
            " [9.94665325e-01]\n",
            " [9.33727920e-01]\n",
            " [1.51687741e-01]\n",
            " [8.84775400e-01]\n",
            " [1.65641308e-04]\n",
            " [7.15255737e-07]\n",
            " [9.72058296e-01]\n",
            " [9.74915624e-01]\n",
            " [9.74401414e-01]\n",
            " [3.29825073e-01]\n",
            " [9.78621483e-01]\n",
            " [9.92134154e-01]\n",
            " [7.80463219e-04]\n",
            " [2.84445286e-03]\n",
            " [9.19900298e-01]\n",
            " [9.89060879e-01]\n",
            " [8.31186116e-01]\n",
            " [8.21880639e-01]\n",
            " [8.26556265e-01]\n",
            " [9.69809175e-01]\n",
            " [4.86603677e-02]\n",
            " [9.67504203e-01]\n",
            " [7.53407836e-01]\n",
            " [1.10268593e-06]\n",
            " [6.98904514e-01]\n",
            " [5.87917805e-01]\n",
            " [9.65493381e-01]\n",
            " [9.81151819e-01]\n",
            " [9.98878717e-01]\n",
            " [8.90590310e-01]\n",
            " [8.70888770e-01]\n",
            " [1.04774475e-01]\n",
            " [9.38562453e-01]\n",
            " [9.49795961e-01]\n",
            " [2.39935517e-03]\n",
            " [9.82727051e-01]\n",
            " [9.90155816e-01]\n",
            " [9.81309712e-01]\n",
            " [7.25518942e-01]\n",
            " [9.83639300e-01]\n",
            " [9.99166131e-01]\n",
            " [9.96061802e-01]\n",
            " [9.84085619e-01]\n",
            " [9.62193906e-01]\n",
            " [9.96738970e-01]\n",
            " [9.19644594e-01]\n",
            " [9.93800759e-01]\n",
            " [9.82740521e-01]\n",
            " [9.76714253e-01]\n",
            " [1.56164169e-05]\n",
            " [2.40683556e-03]\n",
            " [8.83221626e-04]\n",
            " [9.97816086e-01]\n",
            " [9.74196911e-01]\n",
            " [9.97769058e-01]\n",
            " [9.51077342e-01]\n",
            " [9.93754983e-01]\n",
            " [5.79711616e-01]\n",
            " [9.21809793e-01]\n",
            " [6.27954245e-01]\n",
            " [2.98970222e-01]\n",
            " [9.95451331e-01]\n",
            " [7.27301836e-03]\n",
            " [9.95009780e-01]\n",
            " [3.34380567e-02]\n",
            " [9.91700768e-01]\n",
            " [9.97135222e-01]\n",
            " [9.87088978e-01]\n",
            " [9.08073783e-03]\n",
            " [4.40058112e-03]\n",
            " [4.47408974e-01]\n",
            " [7.68825412e-01]\n",
            " [1.19057238e-01]\n",
            " [9.51661766e-01]\n",
            " [7.49409199e-04]\n",
            " [9.91679549e-01]\n",
            " [9.86782610e-01]\n",
            " [8.96600485e-01]\n",
            " [9.87118363e-01]\n",
            " [9.30288732e-01]\n",
            " [9.30759013e-02]\n",
            " [3.64880562e-02]\n",
            " [1.53656900e-02]\n",
            " [1.18315220e-05]\n",
            " [5.41394889e-01]\n",
            " [9.95606542e-01]\n",
            " [9.24080789e-01]\n",
            " [9.98772502e-01]\n",
            " [1.62239969e-02]\n",
            " [4.09897029e-01]\n",
            " [3.86267900e-04]\n",
            " [9.81815934e-01]\n",
            " [9.69207525e-01]\n",
            " [9.23709154e-01]\n",
            " [1.72273219e-02]\n",
            " [2.56807804e-01]\n",
            " [9.97170746e-01]\n",
            " [1.76787376e-04]\n",
            " [9.80223715e-01]\n",
            " [1.71560049e-03]\n",
            " [9.85202312e-01]\n",
            " [4.66456980e-01]\n",
            " [9.84363377e-01]\n",
            " [2.35783577e-01]\n",
            " [1.12847894e-01]\n",
            " [4.84228134e-04]\n",
            " [1.16752863e-01]\n",
            " [1.54810846e-02]\n",
            " [9.78476644e-01]\n",
            " [9.67464626e-01]\n",
            " [8.31224620e-02]\n",
            " [9.96892929e-01]\n",
            " [1.53045923e-01]\n",
            " [1.38450474e-01]\n",
            " [9.93314028e-01]\n",
            " [9.44655538e-01]\n",
            " [3.79824460e-01]\n",
            " [9.53740180e-01]\n",
            " [5.21427989e-02]\n",
            " [8.97540152e-01]\n",
            " [9.07244325e-01]\n",
            " [9.35841143e-01]\n",
            " [7.87749887e-01]\n",
            " [9.94510174e-01]\n",
            " [9.80743647e-01]\n",
            " [3.33559990e-01]\n",
            " [9.26254630e-01]\n",
            " [1.81988984e-01]\n",
            " [5.74819088e-01]\n",
            " [1.24853969e-01]\n",
            " [7.08976388e-03]\n",
            " [1.79249677e-04]\n",
            " [2.67851919e-01]\n",
            " [9.49085832e-01]\n",
            " [9.78516221e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GmnZTE8m0Ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "c5df2266-0801-46a1-f989-614060be88f0"
      },
      "source": [
        "# Round to get the actual predictions\n",
        "# Note: has to be flattened since the targets are size (N,) while the predictions are size (N,1)\n",
        "import numpy as np\n",
        "P = np.round(P).flatten()\n",
        "print(P)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.\n",
            " 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1.\n",
            " 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM2KsLrGm2-h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3d0dd5de-c3ed-41f1-99cd-c183cf2f35e4"
      },
      "source": [
        "# Calculate the accuracy, compare it to evaluate() output\n",
        "print(\"Manually calculated accuracy:\", np.mean(P == y_test))\n",
        "print(\"Evaluate output:\", model.evaluate(X_test, y_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Manually calculated accuracy: 0.9787234042553191\n",
            "188/188 [==============================] - 0s 95us/sample - loss: 0.1004 - accuracy: 0.9787\n",
            "Evaluate output: [0.1004109855027909, 0.9787234]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx4-M7hWnMFT",
        "colab_type": "text"
      },
      "source": [
        "# Part 3: Saving and Loading a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PEzm8CsnTbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now save our model to a file\n",
        "model.save('linearclassifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vruk3712nhZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6caad1a8-6bca-4592-f930-554eec3d91b2"
      },
      "source": [
        "# check that the model file exists\n",
        "!ls -lh"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 580K\n",
            "-rw-r--r-- 1 root root 393K Apr  1  1998 arrhythmia.data\n",
            "-rw-r--r-- 1 root root   76 Aug 16 11:21 fake_util.py\n",
            "drwx------ 3 root root 4.0K Aug 16 11:34 gdrive\n",
            "-rw-r--r-- 1 root root  19K Aug 16 13:29 linearclassifier.h5\n",
            "-rw-r--r-- 1 root root 2.3K Aug 16 12:35 moore.csv\n",
            "-rw-r--r-- 1 root root 2.3K Aug 16 13:19 moore.csv.1\n",
            "drwxr-xr-x 2 root root 4.0K Aug 16 11:21 __pycache__\n",
            "drwxr-xr-x 1 root root 4.0K Aug  2 16:06 sample_data\n",
            "-rw-r--r-- 1 root root 137K Aug 16 11:19 wrong_fitments.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRQicX4cnnyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "c874a822-f378-44f6-e97c-880e540c7db1"
      },
      "source": [
        "# Let's load the model and confirm that it still works\n",
        "# Note: there is a bug in Keras where load/save only works if you DON'T use the Input() layer explicitly\n",
        "# So, make sure you define the model with ONLY Dense(1, input_shape=(D,))\n",
        "# At least, until the bug is fixed\n",
        "# https://github.com/keras-team/keras/issues/10417\n",
        "model = tf.keras.models.load_model('linearclassifier.h5')\n",
        "print(model.layers)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f9b0f33b27a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linearclassifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0b1/python3.6/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    135\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    136\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0b1/python3.6/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0b1/python3.6/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    669\u001b[0m                      \u001b[0;34m'containing '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                      \u001b[0;34m' layers into a model with '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                      ' layers.')\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;31m# We batch weight value assignments in a single backend call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You are trying to load a weight file containing 1 layers into a model with 0 layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k7wquornspm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "1c8ae61c-9f00-4ae8-fc72-fe98881836f0"
      },
      "source": [
        "# Download the file - requires Chrome (at this point)\n",
        "from google.colab import files\n",
        "files.download('linearclassifier.h5')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-e644754b1e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linearclassifier.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    }
  ]
}